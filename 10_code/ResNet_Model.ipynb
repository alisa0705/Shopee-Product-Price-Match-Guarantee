{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:55:47.349057: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-04 19:55:48.365336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import pre-processed data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras import applications, layers, losses, optimizers, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras_toolkit as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textwrap import wrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change tensorflow device to GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process image data so that it can be used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.csv',\n",
       " 'sample_submission.csv',\n",
       " 'train_images',\n",
       " 'test.csv',\n",
       " 'test_images']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/'\n",
    "PATH_TO_IMG = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/train_images/'\n",
    "PATH_TO_TEST = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/test_images/'\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32411"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many images are there in trainig set\n",
    "len(os.listdir(PATH_TO_IMG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPUTE_CV = True\n",
    "if len(pd.read_csv(PATH + 'test.csv')) > 3: COMPUTE_CV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_CV:\n",
    "    dataset = pd.read_csv(PATH + 'train.csv')\n",
    "    tmp = dataset.groupby('label_group').posting_id.agg('unique').to_dict() \n",
    "    dataset['target'] = dataset.label_group.map(tmp) # map the posting_ids that have same image\n",
    "else:    \n",
    "    dataset = pd.read_csv(PATH + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_img():\n",
    "    # choose randomly two instances per each class\n",
    "    labels_to_show = np.random.choice(dataset.label_group.unique(), \n",
    "                                      replace=False, size=27)\n",
    "    img_to_show = []\n",
    "    for label in labels_to_show:\n",
    "        rows = dataset[dataset.label_group==label].copy()\n",
    "        pair = np.random.choice([i for i in range(len(rows))], \n",
    "                                    replace=False, size=2)\n",
    "        img_pair = rows.iloc[pair][['image', 'title']].values\n",
    "        \n",
    "        img_to_show += list(img_pair)\n",
    "    \n",
    "    fig, axes = plt.subplots(figsize = (18, 12), nrows=4,ncols=6)\n",
    "    for imp, ax in zip(img_to_show, axes.ravel()):\n",
    "        img = cv2.imread(PATH_TO_IMG + imp[0])\n",
    "        title = '\\n'.join(wrap(imp[1], 20))\n",
    "        ax.set_title(title)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_CV:\n",
    "    show_random_img()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganize the data into a directory structure that can be used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 20_intermediate_data folder if not exist\n",
    "if not os.path.exists('/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data'):\n",
    "    os.mkdir('/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data')\n",
    "    print(\"Folder Created\")\n",
    "else:\n",
    "    print(\"Folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for each class\n",
    "for label in dataset.label_group.unique():\n",
    "    if not os.path.exists('/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data/' + str(label)):\n",
    "        os.mkdir('/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data/' + str(label))\n",
    "        print(\"Folder Created\")\n",
    "    else:\n",
    "        print(\"Folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy images to their respective class folder\n",
    "for label in dataset.label_group.unique():\n",
    "    for img in dataset[dataset.label_group==label].image.values:\n",
    "        os.system('cp ' + PATH_TO_IMG + img + ' /workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data/' + str(label) + '/')\n",
    "        print(\"Image copied\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32459 files belonging to 11014 classes.\n",
      "Using 25968 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:56:21.423142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14575 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32459 files belonging to 11014 classes.\n",
      "Using 6491 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# create train and validation set\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data/',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=17,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data/',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=17,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:56:29.726080: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [25968]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-04 19:56:29.726444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [25968]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3)\n",
      "(32, 11014)\n"
     ]
    }
   ],
   "source": [
    "# check the image size\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 11014 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_ds.class_names)\n",
    "print(f\"We have {num_classes} classes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "# print(class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize 6 images from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plotter_lib\n",
    "\n",
    "plotter_lib.figure(figsize=(10, 10))\n",
    "\n",
    "epochs=10\n",
    "\n",
    "for images, labels in train_ds.take(1):\n",
    "\n",
    "  for var in range(6):\n",
    "\n",
    "    ax = plt.subplot(3, 3, var + 1)\n",
    "\n",
    "    plotter_lib.imshow(images[var].numpy().astype(\"uint8\"))\n",
    "\n",
    "    plotter_lib.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the ResNet50 model from keras\n",
    "\n",
    "resnet = Sequential()\n",
    "pretrained_model = applications.ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(256, 256, 3),\n",
    "    pooling='avg',\n",
    "    classes=num_classes\n",
    ")\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet.add(pretrained_model)\n",
    "# add a fully connected layer\n",
    "resnet.add(Flatten())\n",
    "resnet.add(Dense(512, activation='relu'))\n",
    "resnet.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "# save the model\n",
    "# if not os.path.exists('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50'):\n",
    "#     os.mkdir('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50')\n",
    "#     print(\"Folder Created\")\n",
    "#     model.save('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50/resnet50v2.h5')\n",
    "#     print(\"Model Saved\")\n",
    "# else:\n",
    "#     print(\"Folder already exists\")\n",
    "#     model.save('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50/resnet50v2.h5')\n",
    "#     print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11014)             5650182   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,264,070\n",
      "Trainable params: 6,699,270\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10 # set default to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:57:02.861417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-04 19:57:03.517602: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-04 19:57:03.518134: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-04 19:57:03.518195: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2023-04-04 19:57:03.518791: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-04 19:57:03.518885: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:317] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-04-04 19:57:04.163811: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x55ab94ad9fb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-04 19:57:04.163879: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2023-04-04 19:57:04.172930: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-04 19:57:04.201492: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:530] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  /usr/local/cuda-11.8\n",
      "  /usr/local/cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
      "2023-04-04 19:57:04.201842: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-04-04 19:57:04.202143: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-04-04 19:57:04.202189: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "\t [[{{node StatefulPartitionedCall_3}}]]\n",
      "2023-04-04 19:57:04.226380: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-04-04 19:57:04.226644: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-04-04 19:57:04.251178: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-04-04 19:57:04.251439: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-04-04 19:57:04.275239: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:274] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-04-04 19:57:04.275508: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_3' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/usr/local/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/usr/local/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_19139/1582739919.py\", line 5, in <module>\n      history = resnet.fit(train_ds, epochs=epochs, validation_data=val_ds)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_3'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_3}}]] [Op:__inference_train_function_9674]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m resnet\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m history \u001b[39m=\u001b[39m resnet\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49mval_ds)\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'StatefulPartitionedCall_3' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/usr/local/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/usr/local/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_19139/1582739919.py\", line 5, in <module>\n      history = resnet.fit(train_ds, epochs=epochs, validation_data=val_ds)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1174, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 650, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1200, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1250, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/vscode/.venv/lib/python3.11/site-packages/keras/optimizers/optimizer.py\", line 1245, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'StatefulPartitionedCall_3'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall_3}}]] [Op:__inference_train_function_9674]"
     ]
    }
   ],
   "source": [
    "resnet.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "history = resnet.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template code\n",
    "\n",
    "# Data Preparation\n",
    " # training dataset train_ds\n",
    "# validation dataset val_ds\n",
    "\n",
    "# Model Architecture\n",
    "base_model = tf.keras.applications.ResNet50V2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(tf.expand_dims(x, axis=1))\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(train_ds, epochs=num_epochs, batch_size=batch_size, validation_data=val_ds)\n",
    "\n",
    "# Evaluation on validation set\n",
    "model.evaluate(val_ds)\n",
    "\n",
    "\n",
    "# Fine-tuning\n",
    "model.trainable = True\n",
    "fine_tune_at = 100\n",
    "for layer in model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate/10)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "history_fine = model.fit(train_ds, epochs=num_epochs, batch_size=batch_size, validation_data=val_ds)\n",
    "\n",
    "# mkdir for saving model\n",
    "if not os.path.exists('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50'):\n",
    "    os.mkdir('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50')\n",
    "    print(\"Folder Created\")\n",
    "    model.save('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50/resnet50v2.h5')\n",
    "    print(\"Model Saved\")\n",
    "else:\n",
    "    print(\"Folder already exists\")\n",
    "    model.save('/workspaces/Shopee-Price-Match-Guarantee/30_results/ResNet50/resnet50v2.h5')\n",
    "    print(\"Model Saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
