{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from torch import nn\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import *\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.nn import Transformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# import pre-processed data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import keras_toolkit as kt\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv('/workspaces/Shopee-Price-Match-Guarantee/15_after_processed/train.csv')\n",
    "val_dataset = pd.read_csv('/workspaces/Shopee-Price-Match-Guarantee/15_after_processed/val.csv')\n",
    "testing_dataset = pd.read_csv('/workspaces/Shopee-Price-Match-Guarantee/15_after_processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE,IMG_SIZE)\n",
    "img_model = tf.keras.applications.ResNet50(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imageEmbeddings(model,imagePath):\n",
    "    image = tf.keras.preprocessing.image.load_img(imagePath,target_size= size)\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])\n",
    "    img_embeddings = model(input_arr)\n",
    "    meanImgEmb1 = np.mean(img_embeddings,axis =0)\n",
    "    meanImgEmb2 = np.mean(meanImgEmb1,axis=0)\n",
    "    meanImgEmb = np.mean(meanImgEmb2,axis=0)\n",
    "    return meanImgEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings={}\n",
    "for index,row in  training_dataset.iterrows():\n",
    "    imagePath = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/train_images/'+row[1]\n",
    "    img_emb = get_imageEmbeddings(img_model,imagePath)\n",
    "    image_embeddings[row[0]] = img_emb\n",
    "\n",
    "val_image_embeddings={}\n",
    "for index,row in  val_dataset.iterrows():\n",
    "    imagePath = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/train_images/'+row[1]\n",
    "    img_emb = get_imageEmbeddings(img_model,imagePath)\n",
    "    val_image_embeddings[row[0]] = img_emb\n",
    "\n",
    "test_image_embeddings={}\n",
    "for index,row in  testing_dataset.iterrows():\n",
    "    imagePath = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/train_images/'+row[1]\n",
    "    img_emb = get_imageEmbeddings(img_model,imagePath)\n",
    "    test_image_embeddings[row[0]] = img_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dict = {}\n",
    "f1_dict = {}\n",
    "X_train, X_val, y_train, y_val = image_embeddings, val_image_embeddings, training_dataset.label_group, val_dataset.label_group\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "for k in [1, 2, 3, 5, 10, 25, 50, 100]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_val)\n",
    "\n",
    "    # Evaluate the performance on the test set\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "    acc_dict[k] = accuracy\n",
    "    f1_dict[k] = f1\n",
    "\n",
    "plt.plot(acc_dict.keys(), acc_dict.values(), label='accuracy')\n",
    "plt.plot(f1_dict.keys(), f1_dict.values(), label='f1 score')\n",
    "plt.legend()\n",
    "plt.title('Tuning Number of Neighbors')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_image_embeddings, testing_dataset.label_group\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'Accuracy = {accuracy}')\n",
    "print(f'F1 score = {f1}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
