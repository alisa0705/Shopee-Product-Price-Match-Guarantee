{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\n\nfrom torch import nn\nimport nltk\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sentence_transformers import *\nimport torchvision.models as models\n\n\nimport torch.nn as nn\nfrom transformers import BertModel, BertTokenizer\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom sklearn.neighbors import NearestNeighbors\nfrom torch.nn import Transformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n\n# import pre-processed data\nimport pandas as pd\nimport numpy as np\nimport os\n#import cv2\nimport matplotlib.pyplot as plt\nimport PIL\nimport tensorflow as tf\n#import keras_toolkit as kt\nimport keras.backend as K\nfrom sklearn.model_selection import train_test_split\nfrom textwrap import wrap","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:45:51.716020Z","iopub.execute_input":"2023-04-16T14:45:51.716737Z","iopub.status.idle":"2023-04-16T14:45:58.480226Z","shell.execute_reply.started":"2023-04-16T14:45:51.716700Z","shell.execute_reply":"2023-04-16T14:45:58.479219Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# process text\nimport string\nimport re\nfrom nltk.corpus import stopwords\nimport pandas as pd\n\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# remove numbers\ndef remove_numbers(text):\n    'Remove all the numbers from the text'\n    result = re.sub(r'\\d+', '', text)\n    return result\n\n# remove special characters\ndef remove_special_characters(text):\n    'Remove all the special characters from the text'\n    pattern = r'[^a-zA-z0-9\\s]'\n    text = re.sub(pattern, '', text)\n    return text\n\n# remove extra spaces\ndef remove_extra_spaces(text):\n    'remove extra spaces from the text'\n    text = re.sub(' +', ' ', text)\n    return text\n\ndef word_tokenize(text):\n    'tokenize the text'\n    text = text.split()\n    return text\n\n# remove stop words\ndef remove_stop_words(text):\n    'remove stop words from the text'\n    text_tokens = word_tokenize(text)\n    tokens_without_sw = [word for word in text_tokens if not word in stop_words]\n    filtered_sentence = (\" \").join(tokens_without_sw)\n    return filtered_sentence\n\n# remove all preprocessing\ndef remove_all_preprocessing(text):\n    'Remove all the preprocessing from the text'\n    text = remove_numbers(text)\n    text = remove_special_characters(text)\n    text = remove_extra_spaces(text)\n    text = remove_stop_words(text)\n    return text\n\ndef process_text(training_dataset, val_dataset, testing_dataset):\n    'run all process above to clean titles'\n\n    stop_words = set(stopwords.words('english'))\n    punctuations = string.punctuation\n\n    # apply all preprocessing\n    training_dataset['proc_title'] = training_dataset['title'].apply(lambda x: remove_all_preprocessing(x))\n    val_dataset['proc_title'] = val_dataset['title'].apply(lambda x: remove_all_preprocessing(x))\n    testing_dataset['proc_title'] = testing_dataset['title'].apply(lambda x: remove_all_preprocessing(x))\n\n    # get rid of \\\n    training_dataset['proc_title'] = training_dataset['proc_title'].apply(lambda x: x.replace('\\\\', ''))\n    val_dataset['proc_title'] = val_dataset['proc_title'].apply(lambda x: x.replace('\\\\', ''))\n    testing_dataset['proc_title'] = testing_dataset['proc_title'].apply(lambda x: x.replace('\\\\', ''))\n    # lower case\n    training_dataset['proc_title'] = training_dataset['proc_title'].apply(lambda x: x.lower())\n    val_dataset['proc_title'] = val_dataset['proc_title'].apply(lambda x: x.lower())\n    testing_dataset['proc_title'] = testing_dataset['proc_title'].apply(lambda x: x.lower())\n\n    return training_dataset, val_dataset, testing_dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:45:58.481769Z","iopub.execute_input":"2023-04-16T14:45:58.482336Z","iopub.status.idle":"2023-04-16T14:45:58.561494Z","shell.execute_reply.started":"2023-04-16T14:45:58.482308Z","shell.execute_reply":"2023-04-16T14:45:58.560570Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:45:58.562653Z","iopub.execute_input":"2023-04-16T14:45:58.562964Z","iopub.status.idle":"2023-04-16T14:46:08.731245Z","shell.execute_reply.started":"2023-04-16T14:45:58.562936Z","shell.execute_reply":"2023-04-16T14:46:08.730292Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntraining_dataset = pd.read_csv('/kaggle/input/15-after-processed/15_after_processed/train.csv')\nval_dataset = pd.read_csv('/kaggle/input/15-after-processed/15_after_processed/val.csv')\ntesting_dataset = pd.read_csv('/kaggle/input/15-after-processed/15_after_processed/test.csv')\ntraining_dataset, val_dataset, testing_dataset = process_text(training_dataset, val_dataset, testing_dataset)\ntraining_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:46:08.733233Z","iopub.execute_input":"2023-04-16T14:46:08.733506Z","iopub.status.idle":"2023-04-16T14:46:09.447017Z","shell.execute_reply.started":"2023-04-16T14:46:08.733481Z","shell.execute_reply":"2023-04-16T14:46:09.446085Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"         posting_id                                 image       image_phash   \n0  train_2249428809  40d304f91be807fed3b796a158a034f7.jpg  bc69d33e86b491c1  \\\n1  train_1453612941  e05aa71652e2546dbc2a6a2d18cc4aa7.jpg  bcfcc1a80ee930da   \n2   train_414717665  0c0f97f726132be83c7b84e0ca9e604e.jpg  bc4aa5a5de34d2e0   \n3   train_404098311  fedf1394058d6e439698356c0be6f4d6.jpg  cbceb1a14e8bf046   \n4   train_653040440  cfb08184ebbef7a5409e1bd1a0f6d0d9.jpg  c44eec61e516d2b9   \n\n                                               title  label_group   \n0   AMTECH Klem C Set 3 Pcs - Catok Clamp 1 2 3 Inch   3685949317  \\\n1  Cetakan Kue Pukis 10 Lubang Pancong Teflon Ran...   2236232282   \n2  (COD)TAS TOTE BAG T76 TAS CANVAS FASHION WANIT...   3145779110   \n3  (1kg=7pcs) MEIRA CARDIGAN CARDI OUTHER TANPA J...   4171236554   \n4  Wardah Lightening Day Cream 30gr or  night cre...   1774190279   \n\n                                          proc_title  \n0             amtech klem c set pcs catok clamp inch  \n1  cetakan kue pukis lubang pancong teflon rangin...  \n2  codtas tote bag t tas canvas fashion wanita im...  \n3     kgpcs meira cardigan cardi outher tanpa jilbab  \n4      wardah lightening day cream gr night cream gr  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>posting_id</th>\n      <th>image</th>\n      <th>image_phash</th>\n      <th>title</th>\n      <th>label_group</th>\n      <th>proc_title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_2249428809</td>\n      <td>40d304f91be807fed3b796a158a034f7.jpg</td>\n      <td>bc69d33e86b491c1</td>\n      <td>AMTECH Klem C Set 3 Pcs - Catok Clamp 1 2 3 Inch</td>\n      <td>3685949317</td>\n      <td>amtech klem c set pcs catok clamp inch</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1453612941</td>\n      <td>e05aa71652e2546dbc2a6a2d18cc4aa7.jpg</td>\n      <td>bcfcc1a80ee930da</td>\n      <td>Cetakan Kue Pukis 10 Lubang Pancong Teflon Ran...</td>\n      <td>2236232282</td>\n      <td>cetakan kue pukis lubang pancong teflon rangin...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_414717665</td>\n      <td>0c0f97f726132be83c7b84e0ca9e604e.jpg</td>\n      <td>bc4aa5a5de34d2e0</td>\n      <td>(COD)TAS TOTE BAG T76 TAS CANVAS FASHION WANIT...</td>\n      <td>3145779110</td>\n      <td>codtas tote bag t tas canvas fashion wanita im...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_404098311</td>\n      <td>fedf1394058d6e439698356c0be6f4d6.jpg</td>\n      <td>cbceb1a14e8bf046</td>\n      <td>(1kg=7pcs) MEIRA CARDIGAN CARDI OUTHER TANPA J...</td>\n      <td>4171236554</td>\n      <td>kgpcs meira cardigan cardi outher tanpa jilbab</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_653040440</td>\n      <td>cfb08184ebbef7a5409e1bd1a0f6d0d9.jpg</td>\n      <td>c44eec61e516d2b9</td>\n      <td>Wardah Lightening Day Cream 30gr or  night cre...</td>\n      <td>1774190279</td>\n      <td>wardah lightening day cream gr night cream gr</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    dist_model = SentenceTransformer('stsb-distilbert-base')\n    dist_model.max_seq_length = 128\n\ntrain_titles = training_dataset.proc_title.tolist()\ntrain_embed = dist_model.encode(train_titles, show_progress_bar=True, convert_to_tensor=True)\n\nval_titles = val_dataset.proc_title.tolist()\nval_embed = dist_model.encode(val_titles, show_progress_bar=True, convert_to_tensor=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:46:09.448203Z","iopub.execute_input":"2023-04-16T14:46:09.448518Z","iopub.status.idle":"2023-04-16T14:47:09.708502Z","shell.execute_reply.started":"2023-04-16T14:46:09.448490Z","shell.execute_reply":"2023-04-16T14:47:09.706878Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Batches: 100%|██████████| 685/685 [00:47<00:00, 14.51it/s]\nBatches: 100%|██████████| 172/172 [00:11<00:00, 14.65it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"IMG_SIZE = 224\nsize = (IMG_SIZE,IMG_SIZE)\nwith tpu_strategy.scope():\n    img_model = tf.keras.applications.MobileNet(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet' )\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-16T14:47:09.710161Z","iopub.execute_input":"2023-04-16T14:47:09.710530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_textEmbeddings(model,text):\n    text_embedding = model.encode(text, convert_to_tensor=True)\n    return text_embedding\n\ndef get_imageEmbeddings(model,imagePath):\n    image = tf.keras.preprocessing.image.load_img(imagePath,target_size= size)\n    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n    input_arr = np.array([input_arr])\n    img_embeddings = model(input_arr)\n    meanImgEmb1 = np.mean(img_embeddings,axis =0)\n    meanImgEmb2 = np.mean(meanImgEmb1,axis=0)\n    meanImgEmb = np.mean(meanImgEmb2,axis=0)\n    return meanImgEmb\n\nX_train, X_val, y_train, y_val = train_embed, val_embed, training_dataset.label_group, val_dataset.label_group","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_embeddings={}\nimage_embeddings={}\nwith tpu_strategy.scope():\n    for index,row in  training_dataset.iterrows():\n        txt_emb = get_textEmbeddings(dist_model,str(row['proc_title']))\n        imagePath = '/kaggle/input/shopee-product-matching/train_images/'+row[1]\n        img_emb = get_imageEmbeddings(img_model,imagePath)\n        text_embeddings[row[0]] = txt_emb\n        image_embeddings[row[0]] = img_emb\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_text_embeddings={}\nval_image_embeddings={}\nwith tpu_strategy.scope():\n    for index,row in  val_dataset.iterrows():\n        txt_emb = get_textEmbeddings(dist_model,str(row['proc_title']))\n        imagePath = '/kaggle/input/shopee-product-matching/train_images/'+row[1]\n        img_emb = get_imageEmbeddings(img_model,imagePath)\n        val_text_embeddings[row[0]] = txt_emb\n        val_image_embeddings[row[0]] = img_emb\n\ntest_text_embeddings={}\ntest_image_embeddings={}\nwith tpu_strategy.scope():\n    for index,row in  testing_dataset.iterrows():\n        txt_emb = get_textEmbeddings(dist_model,str(row['proc_title']))\n        imagePath = '/kaggle/input/shopee-product-matching/train_images/'+row[1]\n        img_emb = get_imageEmbeddings(img_model,imagePath)\n        test_text_embeddings[row[0]] = txt_emb\n        test_image_embeddings[row[0]] = img_emb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keyList=[]\ncembList=[]\nimageList=[]\ntitleList=[]\nfor index, row in training_dataset.iterrows():\n    txt_emb = text_embeddings[row[0]].cpu().numpy()\n    img_emb = image_embeddings[row[0]]\n    cmb_emb = np.concatenate((txt_emb,img_emb),axis=0)\n\n    norm = np.linalg.norm(cmb_emb)\n    cmb_emb_normal = cmb_emb/norm\n    \n    keyList.append(row[0])\n    cembList.append(cmb_emb_normal)\n    imageList.append(row['image'])\n    titleList.append(row['proc_title'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc_dict = {}\nf1_dict = {}\nX_train, X_val, y_train, y_val = cembList, val_cembList, training_dataset.label_group, val_dataset.label_group\n\n\nfrom sklearn.metrics import accuracy_score, f1_score\nfor k in [1, 2, 3, 5, 10, 25, 50, 100]:\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    y_pred = knn.predict(X_val)\n\n    # Evaluate the performance on the test set\n    accuracy = accuracy_score(y_val, y_pred)\n    f1 = f1_score(y_val, y_pred, average='weighted')\n    acc_dict[k] = accuracy\n    f1_dict[k] = f1\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(acc_dict.keys(), acc_dict.values(), label='accuracy')\nplt.plot(f1_dict.keys(), f1_dict.values(), label='f1 score')\nplt.legend()\nplt.title('Tuning Number of Neighbors')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Score')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keyList=[]\ntest_cembList=[]\ntest_imageList=[]\ntest_titleList=[]\n\nfor index, row in testing_dataset.iterrows():\n    txt_emb = test_text_embeddings[row[0]].cpu().numpy()\n    img_emb = test_image_embeddings[row[0]]\n    cmb_emb = np.concatenate((txt_emb,img_emb),axis=0)\n\n    norm = np.linalg.norm(cmb_emb)\n    cmb_emb_normal = cmb_emb/norm\n    \n    keyList.append(row[0])\n    test_cembList.append(cmb_emb_normal)\n    test_imageList.append(row['image'])\n    test_titleList.append(row['proc_title'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test, y_test = test_cembList, testing_dataset.label_group\n\nknn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred, average='weighted')\nprint(f'Accuracy = {accuracy}')\nprint(f'F1 score = {f1}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}