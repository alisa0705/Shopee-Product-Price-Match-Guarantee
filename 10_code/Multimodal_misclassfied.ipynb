{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from torch import nn\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import *\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.nn import Transformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# import pre-processed data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_process import process_text\n",
    "training_dataset = pd.read_csv('/workspaces/Shopee-Price-Match-Guarantee/15_after_processed/train.csv')\n",
    "val_dataset = pd.read_csv('/workspaces/Shopee-Price-Match-Guarantee/15_after_processed/val.csv')\n",
    "testing_dataset = pd.read_csv('/workspaces/Shopee-Price-Match-Guarantee/15_after_processed/test.csv')\n",
    "training_dataset, val_dataset, testing_dataset = process_text(training_dataset, val_dataset, testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 685/685 [01:13<00:00,  9.38it/s]\n",
      "Batches: 100%|██████████| 172/172 [00:17<00:00,  9.81it/s]\n"
     ]
    }
   ],
   "source": [
    "dist_model = SentenceTransformer('stsb-distilbert-base')\n",
    "dist_model.max_seq_length = 128\n",
    "\n",
    "train_titles = training_dataset.proc_title.tolist()\n",
    "train_embed = dist_model.encode(train_titles, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n",
    "val_titles = val_dataset.proc_title.tolist()\n",
    "val_embed = dist_model.encode(val_titles, show_progress_bar=True, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE,IMG_SIZE)\n",
    "img_model = tf.keras.applications.MobileNet(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet' )\n",
    "def get_imageEmbeddings(model,imagePath):\n",
    "    image = tf.keras.preprocessing.image.load_img(imagePath,target_size= size)\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    input_arr = np.array([input_arr])\n",
    "    img_embeddings = model(input_arr)\n",
    "    meanImgEmb1 = np.mean(img_embeddings,axis =0)\n",
    "    meanImgEmb2 = np.mean(meanImgEmb1,axis=0)\n",
    "    meanImgEmb = np.mean(meanImgEmb2,axis=0)\n",
    "    return meanImgEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_textEmbeddings(model,text):\n",
    "    text_embedding = model.encode(text, convert_to_tensor=True)\n",
    "    return text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_val, y_train, y_val = train_embed, val_embed, training_dataset.label_group, val_dataset.label_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings={}\n",
    "image_embeddings={}\n",
    "for index,row in  training_dataset.iterrows():\n",
    "    txt_emb = get_textEmbeddings(dist_model,str(row['proc_title']))\n",
    "    imagePath = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/train_images/'+row[1]\n",
    "    img_emb = get_imageEmbeddings(img_model,imagePath)\n",
    "    text_embeddings[row[0]] = txt_emb\n",
    "    image_embeddings[row[0]] = img_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_text_embeddings={}\n",
    "val_image_embeddings={}\n",
    "for index,row in  val_dataset.iterrows():\n",
    "    txt_emb = get_textEmbeddings(dist_model,str(row['proc_title']))\n",
    "    imagePath = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/train_images/'+row[1]\n",
    "    img_emb = get_imageEmbeddings(img_model,imagePath)\n",
    "    val_text_embeddings[row[0]] = txt_emb\n",
    "    val_image_embeddings[row[0]] = img_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyList=[]\n",
    "cembList=[]\n",
    "imageList=[]\n",
    "titleList=[]\n",
    "for index, row in training_dataset.iterrows():\n",
    "    txt_emb = text_embeddings[row[0]].cpu().numpy()\n",
    "    img_emb = image_embeddings[row[0]]\n",
    "    cmb_emb = np.concatenate((txt_emb,img_emb),axis=0)\n",
    "\n",
    "    norm = np.linalg.norm(cmb_emb)\n",
    "    cmb_emb_normal = cmb_emb/norm\n",
    "    \n",
    "    keyList.append(row[0])\n",
    "    cembList.append(cmb_emb_normal)\n",
    "    imageList.append(row['image'])\n",
    "    titleList.append(row['proc_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyList=[]\n",
    "val_cembList=[]\n",
    "imageList=[]\n",
    "titleList=[]\n",
    "for index, row in val_dataset.iterrows():\n",
    "    txt_emb = val_text_embeddings[row[0]].cpu().numpy()\n",
    "    img_emb = val_image_embeddings[row[0]]\n",
    "    cmb_emb = np.concatenate((txt_emb,img_emb),axis=0)\n",
    "\n",
    "    norm = np.linalg.norm(cmb_emb)\n",
    "    cmb_emb_normal = cmb_emb/norm\n",
    "    \n",
    "    keyList.append(row[0])\n",
    "    val_cembList.append(cmb_emb_normal)\n",
    "    imageList.append(row['image'])\n",
    "    titleList.append(row['proc_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = cembList, val_cembList, training_dataset.label_group, val_dataset.label_group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.DataFrame(X_val)\n",
    "y_val = pd.Series(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=1, 2509 out of 5480 data points are misclassified.\n",
      "For k=2, 3179 out of 5480 data points are misclassified.\n",
      "For k=3, 3408 out of 5480 data points are misclassified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "for k in [1, 2, 3]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_val)\n",
    "    \n",
    "    # Find misclassified data points\n",
    "    misclassified_indices = np.where(y_pred != y_val)[0]\n",
    "    misclassified_data = X_val.iloc[misclassified_indices]\n",
    "    misclassified_labels = y_val.iloc[misclassified_indices]\n",
    "    predicted_labels = y_pred[misclassified_indices]\n",
    "    \n",
    "    print(f\"For k={k}, {len(misclassified_indices)} out of {len(y_val)} data points are misclassified.\")\n",
    "    \n",
    "    for i in misclassified_indices:\n",
    "        result = {'K': k, 'True label': y_val.iloc[i], 'Predicted label': y_pred[i]}\n",
    "        results.append(result)\n",
    "    \n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>True label</th>\n",
       "      <th>Predicted label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>631365480</td>\n",
       "      <td>3019357193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3651485151</td>\n",
       "      <td>3441184770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>663012346</td>\n",
       "      <td>3151399095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1761007187</td>\n",
       "      <td>3319810322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4069659242</td>\n",
       "      <td>2158225477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   K  True label  Predicted label\n",
       "0  1   631365480       3019357193\n",
       "1  1  3651485151       3441184770\n",
       "2  1   663012346       3151399095\n",
       "3  1  1761007187       3319810322\n",
       "4  1  4069659242       2158225477"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv='/workspaces/Shopee-Price-Match-Guarantee/30_results/Multimodal_missclassified.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(path_to_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
