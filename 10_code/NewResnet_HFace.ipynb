{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras import applications, layers, losses, optimizers, Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from textwrap import wrap\n",
    "from transformers import ResNetConfig, ResNetModel\n",
    "from transformers import AutoImageProcessor, TFResNetForImageClassification\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFResNetForImageClassification.\n",
      "\n",
      "All the layers of TFResNetForImageClassification were initialized from the model checkpoint at microsoft/resnet-50.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFResNetForImageClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = TFResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/'\n",
    "PATH_TO_IMG = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/train_images/'\n",
    "PATH_TO_TEST = '/workspaces/Shopee-Price-Match-Guarantee/00_source_data/shopee-product-matching/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32459 files belonging to 11014 classes.\n",
      "Using 25968 files for training.\n",
      "Found 32459 files belonging to 11014 classes.\n",
      "Using 6491 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# create train and validation set\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data/',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224), # change from 256 to 224\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    '/workspaces/Shopee-Price-Match-Guarantee/20_intermediate_data/',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(224, 224),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/workspaces/Shopee-Price-Match-Guarantee/30_results/HG_ResNet50/checkpoints/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "\n",
    "# import the ResNet50 model from keras\n",
    "\n",
    "resnet = Sequential()\n",
    "pretrained_model = applications.ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3), # change from 256 to 224\n",
    "    pooling='avg',\n",
    "    classes=num_classes,\n",
    "    classifier_activation='softmax',\n",
    ")\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "resnet.add(pretrained_model)\n",
    "# add batch normalization layer\n",
    "resnet.add(BatchNormalization())\n",
    "# flatten the output\n",
    "resnet.add(Flatten())\n",
    "# add dropout layer\n",
    "resnet.add(Dropout(0.5))\n",
    "# add linear layer for reduction\n",
    "resnet.add(Dense(512, activation='linear'))\n",
    "# add classification layer\n",
    "resnet.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5 \n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugging faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFResNetForImageClassification.\n",
      "\n",
      "All the layers of TFResNetForImageClassification were initialized from the model checkpoint at microsoft/resnet-50.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFResNetForImageClassification for predictions without further training.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Layer resnet has no inbound nodes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m pretrained_model \u001b[39m=\u001b[39m TFResNetForImageClassification\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mmicrosoft/resnet-50\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# remove the classification head\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m pretrained_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39mpretrained_model\u001b[39m.\u001b[39minputs, outputs\u001b[39m=\u001b[39mpretrained_model\u001b[39m.\u001b[39;49mlayers[\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39;49moutput)\n\u001b[1;32m     10\u001b[0m resnet \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m     11\u001b[0m resnet\u001b[39m.\u001b[39madd(pretrained_model)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py:2082\u001b[0m, in \u001b[0;36mLayer.output\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[39m\"\"\"Retrieves the output tensor(s) of a layer.\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \n\u001b[1;32m   2070\u001b[0m \u001b[39mOnly applicable if the layer has exactly one output,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[39m  RuntimeError: if called in Eager mode.\u001b[39;00m\n\u001b[1;32m   2080\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2081\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inbound_nodes:\n\u001b[0;32m-> 2082\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   2083\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m has no inbound nodes.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2084\u001b[0m     )\n\u001b[1;32m   2085\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_node_attribute_at_index(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput_tensors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer resnet has no inbound nodes."
     ]
    }
   ],
   "source": [
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "# import the ResNet50 model from transformers\n",
    "pretrained_model = TFResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# remove the classification head\n",
    "pretrained_model = tf.keras.Model(inputs=pretrained_model.inputs, outputs=pretrained_model.layers[-2].output)\n",
    "\n",
    "resnet = Sequential()\n",
    "resnet.add(pretrained_model)\n",
    "\n",
    "# add batch normalization layer\n",
    "resnet.add(BatchNormalization())\n",
    "# flatten the output\n",
    "resnet.add(Flatten())\n",
    "# add dropout layer\n",
    "resnet.add(Dropout(0.5))\n",
    "# add linear layer for reduction\n",
    "resnet.add(Dense(512, activation='linear'))\n",
    "# add classification layer\n",
    "resnet.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "resnet.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[get_f1])\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    # monitor='val_loss',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch')\n",
    "\n",
    "\n",
    "\n",
    "resnet.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFResNetForImageClassification.\n",
      "\n",
      "All the layers of TFResNetForImageClassification were initialized from the model checkpoint at microsoft/resnet-50.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFResNetForImageClassification for predictions without further training.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Layer tf_res_net_for_image_classification_2 is not connected, no input to return.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m pretrained_model \u001b[39m=\u001b[39m TFResNetForImageClassification\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mmicrosoft/resnet-50\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[39m# remove the classification head\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m pretrained_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39mpretrained_model\u001b[39m.\u001b[39;49minput, outputs\u001b[39m=\u001b[39mpretrained_model\u001b[39m.\u001b[39mlayers[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39moutput)\n\u001b[1;32m     15\u001b[0m resnet \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m     16\u001b[0m resnet\u001b[39m.\u001b[39madd(pretrained_model)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/keras/engine/base_layer.py:2061\u001b[0m, in \u001b[0;36mLayer.input\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2048\u001b[0m \u001b[39m\"\"\"Retrieves the input tensor(s) of a layer.\u001b[39;00m\n\u001b[1;32m   2049\u001b[0m \n\u001b[1;32m   2050\u001b[0m \u001b[39mOnly applicable if the layer has exactly one input,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[39m  AttributeError: If no inbound nodes are found.\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inbound_nodes:\n\u001b[0;32m-> 2061\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   2062\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLayer \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m is not connected, no input to return.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2063\u001b[0m     )\n\u001b[1;32m   2064\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_node_attribute_at_index(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput_tensors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer tf_res_net_for_image_classification_2 is not connected, no input to return."
     ]
    }
   ],
   "source": [
    "from transformers import TFResNetForImageClassification\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "# import the ResNet50 model from transformers\n",
    "pretrained_model = TFResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# remove the classification head\n",
    "pretrained_model = tf.keras.Model(inputs=pretrained_model.input, outputs=pretrained_model.layers[-3].output)\n",
    "\n",
    "resnet = Sequential()\n",
    "resnet.add(pretrained_model)\n",
    "\n",
    "# add batch normalization layer\n",
    "resnet.add(BatchNormalization())\n",
    "# flatten the output\n",
    "resnet.add(Flatten())\n",
    "# add dropout layer\n",
    "resnet.add(Dropout(0.5))\n",
    "# add linear layer for reduction\n",
    "resnet.add(Dense(512, activation='linear'))\n",
    "# add classification layer\n",
    "resnet.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "def get_f1(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "resnet.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=[get_f1])\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    # monitor='val_loss',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1,\n",
    "    save_freq='epoch')\n",
    "\n",
    "# load checkpoint if exist\n",
    "# resnet.load_weights(checkpoint_filepath)\n",
    "\n",
    "resnet.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[model_checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
